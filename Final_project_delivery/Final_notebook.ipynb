{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import dash\n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "from dash.dependencies import Input, Output\n",
    "from plotly import graph_objs as go\n",
    "from datetime import datetime\n",
    "from sklearn import linear_model\n",
    "from scipy import signal\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    '''\n",
    "    This function gets the data through REST API\n",
    "    The COVID-19 data source in the API is from Johns Hopkins CSSE\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Pandas dataframe of COVID-19 data    \n",
    "    \n",
    "    '''\n",
    "    data_path = '../data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw = pd.read_csv(data_path)\n",
    "    pd_data_base = pd_raw.rename(columns={'Country/Region': 'country','Province/State': 'state'})\n",
    "    \n",
    "    pd_data_base = pd_data_base.drop(['Lat', 'Long'], axis=1)\n",
    "    pd_data_base.head()\n",
    "    pd_relational_model = pd_data_base.set_index(['state','country']).T.stack(level=[0, 1]).reset_index().rename(columns={'level_0': 'date',0: 'confirmed'})\n",
    "\n",
    "    pd_relational_model['date'] = pd_relational_model['date'].astype('datetime64[ns]')\n",
    "        \n",
    "    #Collecting overall country data for USA\n",
    "    #US_Data = pd_relational_model[(pd_relational_model['country']=='United States of America')].reset_index(drop=True)\n",
    "        \n",
    "    #Deleting the city wise distribution of the US data from the original dataframe\n",
    "    #dataframe = pd_relational_model.drop(pd_relational_model[df_plot['country'] == 'United States of America'].index).reset_index(drop=True)\n",
    "        \n",
    "    #Groupby apply to get the daily status for each country \n",
    "    df_input = pd_relational_model.groupby(['country','date']).agg(np.sum).reset_index()\n",
    "\n",
    "    #Appending the US data to the original dataframe\n",
    "    #df_input = data_frame.append(US_Data, ignore_index=True)\n",
    "    \n",
    "    return df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choropleth_map(input_df):\n",
    "    '''\n",
    "    creates a choropleth graph object\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    Dataframe of the current day COVID-19 stats\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    fig3: plotly choropleth map graph object\n",
    "    \n",
    "    '''\n",
    "    fig3 = go.Figure(\n",
    "        data=go.Choropleth(\n",
    "            locations=input_df['country'],\n",
    "            locationmode='country names',\n",
    "            z=input_df['confirmed'],\n",
    "            #text=input_df['Deaths'],\n",
    "            #hovertext=input_df['Recovered'],\n",
    "            colorscale = 'Blues',\n",
    "            marker_line_color='darkgray',\n",
    "            marker_line_width=0.5,\n",
    "            colorbar_title = 'Confirmed Cases<br>as of<br>'+str(input_df.loc[0,'date']),\n",
    "            hovertemplate = input_df.country + \"<br>Confirmed Cases: %{z} <br> %{hovertext}<extra></extra>\"\n",
    "            )\n",
    "        )\n",
    "    fig3.update_layout(\n",
    "        height=600, margin={\"r\":10,\"t\":50,\"l\":10,\"b\":10}, template='plotly_dark',\n",
    "        title_text='World map to visualise the spread of COVID-19', title_x=0.5)\n",
    "                \n",
    "    return fig3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubling_rate(df_input, clmn='confirmed'):\n",
    "    '''\n",
    "    Helper function to group-by calculate the doubling time\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    df_input: pandas Dataframe\n",
    "    clmn: The column on which the doubling rate is calculated \n",
    "                (Confirmed or confirmed_filtered)\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    df_output: Pandas dataframe with the additional columns\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    pd_DR_result = df_input.groupby('country').apply(rolling_reg, clmn).reset_index()\n",
    "\n",
    "    pd_DR_result = pd_DR_result.rename(columns ={clmn:clmn+'_DR','level_1':'index'})\n",
    "\n",
    "    #Merging the dataset with doubling rate column with the original dataframe\n",
    "    \n",
    "    df_output = pd.merge(df_input,pd_DR_result[['index',str(clmn+'_DR')]],left_index=True,right_on=['index'],how='left')\n",
    "    df_output = df_output.drop(columns=['index'])\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        intercept/slope (Doubling rate): double\n",
    "    '''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept = reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "    return intercept/slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_reg(df_input, col='confirmed'):\n",
    "    ''' Rolling Regression to approximate the doubling time'\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        col: str - Confirmed or Confirmed_filtered column\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        result: Pandas DataFrame\n",
    "    '''\n",
    "    days_back = 3\n",
    "    result = df_input[col].rolling(\n",
    "                window = days_back,\n",
    "                min_periods = days_back).apply(doubling_time_via_regression, raw = False)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df_input,column='confirmed'):\n",
    "    '''  Helper function to apply savgol filter to filter the data in confirmed or confirmed_filtered column\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        column: str - Confirmed or Confirmed_filtered column\n",
    "            \n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: Pandas DataFrame with merged additional columns\n",
    "    \n",
    "    '''\n",
    "\n",
    "    df_output = df_input.copy() \n",
    "\n",
    "    pd_filtered_result = df_output[['country',column]].groupby(['country']).apply(savgol_filter)#.reset_index()\n",
    "\n",
    "    df_output = pd.merge(df_output,pd_filtered_result[[str(column+'_filtered')]],left_index=True,right_index=True,how='left')\n",
    "   \n",
    "    return df_output.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savgol_filter(df_input,column='confirmed',window=5):\n",
    "    ''' Savgol Filter to filter the data in confirmed or confirmed_filtered column  \n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input : pandas.series\n",
    "        column : str - Confirmed or Confirmed_filtered column\n",
    "        window : int - window size (or number of data points) used to filter data\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_result: Pandas DataFrame\n",
    "            the index of the df_input is retained to merge the dataset in filter_data\n",
    "    '''\n",
    "\n",
    "    df_result = df_input\n",
    "\n",
    "    filter_in = df_input[column].fillna(0)\n",
    "\n",
    "    result = signal.savgol_filter(np.array(filter_in), window, 1)\n",
    "    \n",
    "    df_result[str(column+'_filtered')] = result\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the covid-19 data through REST API\n",
    "covid_data = get_data()\n",
    "#Dataframe for the choropleth map\n",
    "df_map = covid_data.loc[covid_data['date']==covid_data['date'].max()].reset_index(drop=True)\n",
    "df_map['date'] = pd.to_datetime(df_map['date']).dt.date\n",
    "\n",
    "pd_api_data = covid_data[['country', 'date', 'confirmed']]\n",
    "\n",
    "#To obtain the filtered data for the confirmed cases\n",
    "final_df = filter_data(pd_api_data)\n",
    "\n",
    "#Calculating the doubling rate for confirmed and confirmed filtered column\n",
    "final_df = doubling_rate(final_df).reset_index(drop=True)\n",
    "final_df = doubling_rate(final_df,'confirmed_filtered').reset_index(drop=True)\n",
    "\n",
    "#Defining a mask to have doubling rate values for confirmed cases more than 100\n",
    "mask = final_df['confirmed']>100\n",
    "final_df['confirmed_filtered_DR'] = final_df['confirmed_filtered_DR'].where(mask, other=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>confirmed_filtered</th>\n",
       "      <th>confirmed_DR</th>\n",
       "      <th>confirmed_filtered_DR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175115</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>254387.0</td>\n",
       "      <td>254390.4</td>\n",
       "      <td>2191.658046</td>\n",
       "      <td>2258.185317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175116</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2022-06-16</td>\n",
       "      <td>254502.0</td>\n",
       "      <td>254510.0</td>\n",
       "      <td>1465.982709</td>\n",
       "      <td>2030.220271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175117</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>254753.0</td>\n",
       "      <td>254639.2</td>\n",
       "      <td>1390.969035</td>\n",
       "      <td>2045.926045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175118</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2022-06-18</td>\n",
       "      <td>254753.0</td>\n",
       "      <td>254747.1</td>\n",
       "      <td>2029.237716</td>\n",
       "      <td>2147.887811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175119</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2022-06-19</td>\n",
       "      <td>254801.0</td>\n",
       "      <td>254855.0</td>\n",
       "      <td>10615.375000</td>\n",
       "      <td>2360.955514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            country       date  confirmed  confirmed_filtered  confirmed_DR  \\\n",
       "0       Afghanistan 2020-01-22        0.0                 0.0           NaN   \n",
       "1       Afghanistan 2020-01-23        0.0                 0.0           NaN   \n",
       "2       Afghanistan 2020-01-24        0.0                 0.0           NaN   \n",
       "3       Afghanistan 2020-01-25        0.0                 0.0           NaN   \n",
       "4       Afghanistan 2020-01-26        0.0                 0.0           NaN   \n",
       "...             ...        ...        ...                 ...           ...   \n",
       "175115     Zimbabwe 2022-06-15   254387.0            254390.4   2191.658046   \n",
       "175116     Zimbabwe 2022-06-16   254502.0            254510.0   1465.982709   \n",
       "175117     Zimbabwe 2022-06-17   254753.0            254639.2   1390.969035   \n",
       "175118     Zimbabwe 2022-06-18   254753.0            254747.1   2029.237716   \n",
       "175119     Zimbabwe 2022-06-19   254801.0            254855.0  10615.375000   \n",
       "\n",
       "        confirmed_filtered_DR  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "...                       ...  \n",
       "175115            2258.185317  \n",
       "175116            2030.220271  \n",
       "175117            2045.926045  \n",
       "175118            2147.887811  \n",
       "175119            2360.955514  \n",
       "\n",
       "[175120 rows x 6 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "app=dash.Dash()\n",
    "\n",
    "app.layout=html.Div(children=[\n",
    "    \n",
    "    dcc.Markdown('''\n",
    "                 # Covid-19 pandemic Dashboard\n",
    "                 ## This dashboard shows the spread of COVID-19 pandemic\n",
    "                 ''', style={\n",
    "                 'fontFamily': 'sans-serif',\n",
    "                 'textAlign': 'center',\n",
    "                 'backgroundColor':'#070B20',\n",
    "                 'margin': '5px',\n",
    "                 'color': '#F9690E',\n",
    "                 'padding': '5px',\n",
    "                 'borderRadius': '5px'}),\n",
    "    \n",
    "    html.Div(dcc.Graph(id='map', figure=choropleth_map(df_map)), style = {\n",
    "                    'width': '100%',\n",
    "                    'borderRadius': '5px',\n",
    "                }),\n",
    "                    \n",
    "    dcc.Markdown('''\n",
    "                 ## The plot below shows the spread of COVID-19 over time for different countries in the dropdown menu\n",
    "                 ### In the second dropdown, one can select between the actual confirmed and doubling rate\\\n",
    "                 or the filtered confirmed and filtered doubling rate. A savgol filter is used to filter the data\n",
    "                 ''', style={\n",
    "                 'fontFamily': 'sans-serif',\n",
    "                 'textAlign': 'center',\n",
    "                 'backgroundColor':'#070B20',\n",
    "                 'color': '#F39C12',\n",
    "                 'margin': '5px',\n",
    "                 'padding': '5px',\n",
    "                 'borderRadius': '5px'}),\n",
    "                 \n",
    "    dcc.Dropdown(\n",
    "            id='country_drop_down',\n",
    "            options=[{'label': each,'value':each} for each in final_df['country'].unique()],\n",
    "            value=['Germany','United States of America'],\n",
    "            multi=True,\n",
    "            style={'margin': '10px', 'width':'1000px'}\n",
    "        ),\n",
    "    \n",
    "     dcc.Dropdown(\n",
    "        id='stats',\n",
    "        options=[\n",
    "            {'label': 'confirmed ', 'value': 'confirmed'},\n",
    "            {'label': 'Doubling Rate', 'value': 'confirmed_DR'},\n",
    "            {'label': 'confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "            {'label': 'Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'}\n",
    "        ],\n",
    "        value='confirmed',\n",
    "        multi=False,\n",
    "        style={'width':'300px','margin': '10px'}\n",
    "        ),\n",
    "    \n",
    "    dcc.Graph(id='display_stats',style={'width':'100%'}),\n",
    "    \n",
    "    dcc.Markdown('''\n",
    "                 ## SIR model for spread of disease\n",
    "                 ''', style={\n",
    "                 'fontFamily': 'sans-serif',\n",
    "                 'textAlign': 'center',\n",
    "                 'backgroundColor':'#070B20',\n",
    "                 'color': '#F39C12',\n",
    "                 'margin': '5px',\n",
    "                 'padding': '5px',\n",
    "                 'borderRadius': '5px'}),\n",
    "                 \n",
    "    dcc.Dropdown(\n",
    "            id='country_drop_down_sir',\n",
    "            options=[{'label': each,'value':each} for each in final_df['country'].unique()],\n",
    "            value='Germany',\n",
    "            multi=False,\n",
    "            style={'margin': '10px','width':'1000px'}\n",
    "            ),\n",
    "    \n",
    "    dcc.Graph(id='sir_curves', style={'width':'100%'})\n",
    "], style={'backgroundColor':'#B8B8B8'})\n",
    "                             \n",
    "                 \n",
    "@app.callback(\n",
    "    Output('display_stats', 'figure'),\n",
    "    [Input('country_drop_down', 'value'),\n",
    "    Input('stats', 'value')])\n",
    "def update_figure(country_list,show_doubling):\n",
    "\n",
    "\n",
    "    if 'Confirmed_DR' in show_doubling or 'confirmed_filtered_DR' in show_doubling:\n",
    "        my_yaxis={'type':\"log\",\n",
    "               'title':'Approximated doubling rate over 3 days (larger numbers are better)'\n",
    "              }\n",
    "    else:\n",
    "        my_yaxis={'type':\"log\",\n",
    "                  'title':'Confirmed infections (source johns hopkins, log-scale)'\n",
    "              }\n",
    "    \n",
    "    fig1=go.Figure()\n",
    "    for each in country_list:\n",
    "\n",
    "        df_plot=final_df[final_df['country']==each]\n",
    "        df_plot[['country','date','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR',]].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "        fig1.add_traces(go.Scatter(x=df_plot.date, y=df_plot[show_doubling], mode='markers+lines', \n",
    "                                   opacity=0.9, name=each))\n",
    "        fig1.update_layout(template='plotly_dark', height=720,\n",
    "                           xaxis={'title':'Timeline',\n",
    "                          'tickangle':-45,\n",
    "                          'nticks':20,\n",
    "                          'tickfont':dict(size=14,color=\"#FFFFFF\")\n",
    "                          },\n",
    "                           yaxis=my_yaxis\n",
    "                         )\n",
    "\n",
    "    return fig1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('sir_curves', 'figure'),\n",
    "    [Input('country_drop_down_sir', 'value')])\n",
    "\n",
    "def SIR_curves(country_list_sir):\n",
    "    \n",
    "    df_sir=covid_data[covid_data['Country']==country_list_sir].reset_index(drop=True)\n",
    "    ydata=np.array(df_sir[['Confirmed', 'Recovered']].reset_index(drop=True).iloc[20:,])\n",
    "    N0=10000000\n",
    "    \n",
    "    def SIR_model_eq(SIR,t,beta,gamma):\n",
    "        ''' Simple SIR disease spread model\n",
    "            S: susceptible population\n",
    "            t: time step\n",
    "            I: infected people\n",
    "            R: recovered people\n",
    "            beta: Infection rate\n",
    "            gamma: Recovery rate\n",
    "            \n",
    "            S+I+R= N (constant size of population)\n",
    "        '''\n",
    "        S,I,R=SIR\n",
    "        dS_dt=-beta*S*I/N0           \n",
    "        dI_dt=beta*S*I/N0-gamma*I\n",
    "        dR_dt=gamma*I\n",
    "        return dS_dt,dI_dt,dR_dt\n",
    "\n",
    "    def integrate_sir(x, beta, gamma):\n",
    "        \n",
    "        return integrate.odeint(SIR_model_eq, (S0, I0, R0), t, args=(beta, gamma))[:,1] \n",
    "    \n",
    "    fig2=go.Figure()\n",
    "    window_sir = 30\n",
    "    fitted_final=[]\n",
    "    \n",
    "    for i in range(len(ydata)):\n",
    "        if i%window_sir ==0:\n",
    "            if len(ydata[i:])>5:\n",
    "                y_new=ydata[i:i+window_sir,0]\n",
    "                t=np.arange(len(y_new))\n",
    "                #Initialize parameters of SIR model\n",
    "                R0=ydata[i,1]\n",
    "                I0=y_new[0]\n",
    "                S0=N0-I0-R0\n",
    "                #Calculate optimized beta and gamma\n",
    "                popt, pcov = optimize.curve_fit(integrate_sir, t, y_new)\n",
    "                fitted=integrate_sir(t, *popt)\n",
    "                fitted_final.extend(fitted)\n",
    "    \n",
    "    fig2.add_traces(go.Scatter(x=df_sir.Date[20:,], y=fitted_final, mode='markers+lines', \n",
    "                               opacity=0.9, name='SIR estimated'))\n",
    "    \n",
    "    fig2.add_traces(go.Bar(x=df_sir.Date, y=df_sir.Confirmed, opacity=0.7,\n",
    "        name=country_list_sir+' - Confirmed cases'))\n",
    "    \n",
    "    fig2.update_layout(template='plotly_dark', height=720,\n",
    "                xaxis={'title':'Timeline', 'tickangle':-45,'nticks':20,\n",
    "                       'tickfont':dict(size=14,color=\"#FFFFFF\")\n",
    "                       },\n",
    "                yaxis={'type':\"log\",\n",
    "                       'title':'Confirmed infected people'\n",
    "                       })\n",
    "    \n",
    "    return fig2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    app.run_server(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
